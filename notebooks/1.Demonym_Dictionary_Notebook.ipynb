{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: **Can we determine the regions from which Mexican immigrants came to NYC through the traces left in restaurant/tacqueria/deli names?**\n",
    "\n",
    "In this notebook, I'll build the database that will connect words to regions and be used to determine the region that a restaurant is connected to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:46.171526Z",
     "start_time": "2021-03-02T15:14:45.276408Z"
    }
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Maps DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:46.189294Z",
     "start_time": "2021-03-02T15:14:46.173759Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://simplemaps.com/data/mx-cities\n",
    "simple_maps = pd.read_csv(\"../demonym_city_data/mx_simple_maps.csv\")\n",
    "\n",
    "simple_maps_clean_df = simple_maps[['city', 'admin']]\n",
    "simple_maps_clean_df2 = change_df_names(simple_maps_clean_df, 'admin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geonames Data \n",
    "https://public.opendatasoft.com/explore/dataset/geonames-all-cities-with-a-population-1000/export/?disjunctive.country&refine.timezone=America%2FMazatlan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:46.864026Z",
     "start_time": "2021-03-02T15:14:46.192063Z"
    }
   },
   "outputs": [],
   "source": [
    "all_geonames = pd.read_csv(\"../demonym_city_data/geonames_data/all_geonames_cities.csv\", sep=';')\n",
    "\n",
    "mex_geonames = all_geonames[all_geonames['Country'] == 'Mexico']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to convert the number for Admin1_Code to a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:46.886330Z",
     "start_time": "2021-03-02T15:14:46.865875Z"
    }
   },
   "outputs": [],
   "source": [
    "# using simple maps will give us the key\n",
    "regions = list(set(simple_maps.admin.sort_values()))\n",
    "regions.sort()\n",
    "\n",
    "# the regions are in alphabetical order, so I'm using that the code to the right region\n",
    "mex_geonames['Admin1 Code'] = mex_geonames['Admin1 Code'].astype(int)\n",
    "mex_geonames['region'] = [regions[x-1] for x in mex_geonames['Admin1 Code']]\n",
    "\n",
    "# removing name since ascii name covers it without accents\n",
    "mex_geonames_clean_df = mex_geonames[['ASCII Name', 'Alternate Names','region']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining values into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:46.954305Z",
     "start_time": "2021-03-02T15:14:46.887986Z"
    }
   },
   "outputs": [],
   "source": [
    "mex_geonames_clean_df['Alt_names_split'] = [x.split(\",\") if type(x) == str else [] \n",
    "                                            for x in mex_geonames_clean_df['Alternate Names']]\n",
    "\n",
    "mex_geonames_clean_df['ascii_names_list'] = [x.split(\",\") \n",
    "                                            for x in mex_geonames_clean_df['ASCII Name']]\n",
    "\n",
    "mex_geonames_clean_df['all_names_split'] = mex_geonames_clean_df['ascii_names_list'] + mex_geonames_clean_df['Alt_names_split']\n",
    "\n",
    "mex_geonames_clean_df['all_names_split_final'] = [list(set(x)) for x in mex_geonames_clean_df['all_names_split']]\n",
    "mex_geonames_clean_df['all_names_split_unique'] = [list(set(x)) for x in mex_geonames_clean_df['all_names_split_final']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final mex geonames df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:46.967562Z",
     "start_time": "2021-03-02T15:14:46.956553Z"
    }
   },
   "outputs": [],
   "source": [
    "# mex_geonames_clean_df = \n",
    "mex_geonames_clean_df.drop(columns = ['ASCII Name', 'Alternate Names', 'Alt_names_split',\n",
    "                                     'ascii_names_list', 'all_names_split', 'all_names_split_final'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:46.990011Z",
     "start_time": "2021-03-02T15:14:46.969533Z"
    }
   },
   "outputs": [],
   "source": [
    "# mex_geonames_clean_df['region'] = [unidecode.unidecode(x) for x in mex_geonames_clean_df['region']]\n",
    "mex_geonames_clean_df2 = change_df_names(mex_geonames_clean_df, 'region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mexican Cities (world_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.019635Z",
     "start_time": "2021-03-02T15:14:46.992151Z"
    }
   },
   "outputs": [],
   "source": [
    "cities = pd.read_csv(\"../demonym_city_data/world-cities-master/data/world-cities.csv\")\n",
    "\n",
    "mexican_cities = cities[cities['country'] == 'Mexico']\n",
    "mexican_cities_clean_df = mexican_cities[['name', 'subcountry']]\n",
    "mexican_cities_clean_df2 = change_df_names(mexican_cities_clean_df, 'subcountry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mexican Demonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was found using the table found in this wikipedia page: https://en.wikipedia.org/wiki/List_of_adjectival_and_demonymic_forms_of_place_names#States_of_Mexico. Then I entered that link into https://wikitable2csv.ggor.de and downloaded the table as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.029615Z",
     "start_time": "2021-03-02T15:14:47.021362Z"
    }
   },
   "outputs": [],
   "source": [
    "mex_demonyms = pd.read_csv(\"../demonym_city_data/mexican_demonyms.csv\", skip_blank_lines=True, skiprows = [1])\n",
    "mex_demonyms.reset_index(inplace=True)\n",
    "mex_demonyms.drop(index=32, inplace=True)\n",
    "mex_demonyms.columns = ['region', \"region_demonym\", \"adjective\", \"demonym\", 'Demonym.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the names into a single list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing items in \"region_in_spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.033990Z",
     "start_time": "2021-03-02T15:14:47.031153Z"
    }
   },
   "outputs": [],
   "source": [
    "mex_demonyms['region'][14] = \"Ciudad de México\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making list that will host all of the demonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.042608Z",
     "start_time": "2021-03-02T15:14:47.040063Z"
    }
   },
   "outputs": [],
   "source": [
    "# once combined with the previous dataframe, we will have a dictionary with each region having a list of names that could refer to it\n",
    "demonyms = [[x] for x in mex_demonyms['region_demonym'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making each cell only have one term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.060563Z",
     "start_time": "2021-03-02T15:14:47.047823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demonyms[0].append(\"aguascalentense\")\n",
    "\n",
    "mex_demonyms['adjective'][0] = \"Hidrocálido/-a\"\n",
    "\n",
    "demonyms[12].append('Jalisquillo')\n",
    "\n",
    "mex_demonyms['demonym'][12] = \"Tapatio/ Tapatia\"\n",
    "\n",
    "# all of the regions_in_english are in the correct format\n",
    "demonyms[20] = ['Pueblan', 'Poblano']\n",
    "\n",
    "# mex_demonyms['adjective'][0] = \"Hidrocálido/-a\"\n",
    "mex_demonyms['demonym'].replace(np.nan, '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.069569Z",
     "start_time": "2021-03-02T15:14:47.062207Z"
    }
   },
   "outputs": [],
   "source": [
    "## Making all of the -a names to be a seperate entry\n",
    "for x in range(0, len(mex_demonyms)):\n",
    "    multi_adjective = re.match(r\"(\\w+)[o]\\/(?=(\\-?|\\s|\\s\\-)a)(.+)\", mex_demonyms['adjective'][x])\n",
    "    if multi_adjective:\n",
    "        mex_demonyms['adjective'][x] = multi_adjective.group(1) + \"o\" + '/' \\\n",
    "        + multi_adjective.group(1) + \"a\"\n",
    "    multi_dem = re.match(r\"\\\"?(\\w+)[o]\\/(?=(\\-?|\\s|\\s\\-)a)\", mex_demonyms['demonym'][x])\n",
    "    if multi_dem:\n",
    "        mex_demonyms['demonym'][x] = multi_dem.group(1) + \"o\" + '/' \\\n",
    "        + multi_dem.group(1) + \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.076477Z",
     "start_time": "2021-03-02T15:14:47.071473Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting all of items to either be a single name or single name/-a\n",
    "for x in range(0, len(mex_demonyms)):\n",
    "    split_adj = mex_demonyms['adjective'][x].split(\"/\")\n",
    "    for y in split_adj:\n",
    "        demonyms[x].append(y)\n",
    "    split_dem = mex_demonyms['demonym'][x].split(\"/\")\n",
    "    for z in split_dem:\n",
    "        a = z.strip('\"\"')\n",
    "        demonyms[x].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.080729Z",
     "start_time": "2021-03-02T15:14:47.078235Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making the demonyms data only have unique entries\n",
    "unique_demonyms = [list(set(item)) for item in demonyms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the demonyms connect to a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.086395Z",
     "start_time": "2021-03-02T15:14:47.082354Z"
    }
   },
   "outputs": [],
   "source": [
    "demonyms_w_region = list(zip(mex_demonyms['region'], demonyms))\n",
    "demonyms_w_regions_df = pd.DataFrame(data = demonyms_w_region, columns=['State', 'Demonyms'])\n",
    "demonyms_w_regions_df2 = change_df_names(demonyms_w_regions_df, 'State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Mexico_names dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.091362Z",
     "start_time": "2021-03-02T15:14:47.088032Z"
    }
   },
   "outputs": [],
   "source": [
    "english_region_names = list(mexican_cities_clean_df.region.unique())\n",
    "mexico_regional_names_dict = {unidecode.unidecode(x):[] for x in english_region_names} # removing any accents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking that region names match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.098213Z",
     "start_time": "2021-03-02T15:14:47.093619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ciudad de Mexico', 'Coahuila de Zaragoza', 'Michoacan de Ocampo']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_matches_simple_maps = match_region_names(mexico_regional_names_dict, simple_maps_clean_df2)\n",
    "bad_matches_simple_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.104265Z",
     "start_time": "2021-03-02T15:14:47.099998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Michoacan de Ocampo', 'Ciudad de Mexico', 'Coahuila de Zaragoza']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_matches_mex_geonames_clean_df = match_region_names(mexico_regional_names_dict, \n",
    "                                                       mex_geonames_clean_df2)\n",
    "bad_matches_mex_geonames_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.109745Z",
     "start_time": "2021-03-02T15:14:47.105999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_matches_mexican_cities_clean_df = match_region_names(mexico_regional_names_dict, \n",
    "                                                       mexican_cities_clean_df2)\n",
    "bad_matches_mexican_cities_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.115773Z",
     "start_time": "2021-03-02T15:14:47.111658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coahuila de Zaragoza', 'State of Mexico', 'Ciudad de Mexico']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_matches_demonyms_w_regions_df = match_region_names(mexico_regional_names_dict, \n",
    "                                                       demonyms_w_regions_df2)\n",
    "bad_matches_demonyms_w_regions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing incorrect col_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.123101Z",
     "start_time": "2021-03-02T15:14:47.117432Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_maps_clean_df3 = replace_col_values_in_df(simple_maps_clean_df2)\n",
    "mex_geonames_clean_df3 = replace_col_values_in_df(mex_geonames_clean_df2)\n",
    "mexican_cities_clean_df3 = replace_col_values_in_df(mexican_cities_clean_df2)\n",
    "demonyms_w_regions_df3 = replace_col_values_in_df(demonyms_w_regions_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Values to the Larger Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.434887Z",
     "start_time": "2021-03-02T15:14:47.125439Z"
    }
   },
   "outputs": [],
   "source": [
    "mexico_regional_names_dict = add_data_to_dictionary(simple_maps_clean_df3 ,mexico_regional_names_dict)\n",
    "mexico_regional_names_dict = add_data_to_dictionary(mex_geonames_clean_df3 ,mexico_regional_names_dict)\n",
    "mexico_regional_names_dict = add_data_to_dictionary(mexican_cities_clean_df3 ,mexico_regional_names_dict)\n",
    "mexico_regional_names_dict = add_data_to_dictionary(demonyms_w_regions_df3 ,mexico_regional_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.439550Z",
     "start_time": "2021-03-02T15:14:47.436780Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for key, value in mexico_regional_names_dict.items():\n",
    "    counter += len(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.445268Z",
     "start_time": "2021-03-02T15:14:47.441872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22217"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the Larger Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.653308Z",
     "start_time": "2021-03-02T15:14:47.447002Z"
    }
   },
   "outputs": [],
   "source": [
    "mexico_regional_names_dict = clean_dictionary_values(mexico_regional_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.660912Z",
     "start_time": "2021-03-02T15:14:47.655155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the dictionary removed 6731 values\n"
     ]
    }
   ],
   "source": [
    "# getting count of items\n",
    "counter1 = 0\n",
    "for key, value in mexico_regional_names_dict.items():\n",
    "    for thing in value:\n",
    "        counter1 += 1\n",
    "counter1\n",
    "\n",
    "print(f\"Cleaning the dictionary removed {counter - counter1} values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing entries that are ambiguous/mistakenly connected to a region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying bad matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.665676Z",
     "start_time": "2021-03-02T15:14:47.662535Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_matches1 = ['mexican', 'tequila', 'margarita', 'margaritas', 'mexico', 'pedro', 'azteca', 'paraiso'\n",
    "'mexico','rodeo','rio','maria','mexicanos','coyote','marcos','mama','bravo','viejo','perla','nuevo'\n",
    "'verde', 'gonzalez', 'corona', 'armadillo', 'arriba', 'palmas', 'delicias', 'blanco', 'crespo','tortuga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.672169Z",
     "start_time": "2021-03-02T15:14:47.667493Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_matches2 = ['mexican','mexico','mexicanos','azteca','esperanza','estrada','esperanzas','salero','pinos',\n",
    "                  'maria', 'bravo', 'nuevo', 'progreso', 'delicias', 'comales', 'palmas', 'palenque', 'concordia',\n",
    "                 'china', 'gym', 'paloma', 'rio', 'mex', 'tequila', 'colorado', 'ventana', 'lom', 'garcia', 'paz',\n",
    "                 'chavez', 'paraiso', 'senor', 'oriental', 'fronteras', 'tap', 'aca', 'purisima', 'rodriguez',\n",
    "                 'hernandez', 'sanchez', 'victoria', 'oasis', 'cash', 'pinas', 'yaa',  'meson','agustin',\n",
    "                 'agustin', 'limon', 'alamo', 'slp', 'providencia', 'reyes', 'lom', 'verde', 'perla', 'madrid', \n",
    "                 'delta', 'mama', 'lopez', 'honey', 'laurel', 'california pizza kitchen', 'sauces', 'laguna', \n",
    "              'dolores', 'presidio', 'ver', 'bernal', 'rincon', 'marin', 'palma', 'potrero', 'mid', 'valencia',\n",
    "              'aura', 'kava', 'pueblito', 'castillo', 'tam', 'marcos', 'montecristo', 'tinajas', 'alvarado',\n",
    "              'porvenir', 'nieves', 'mina', 'marin', \"alamos\", 'reforma', 'jal', 'margaritas', 'california']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.676778Z",
     "start_time": "2021-03-02T15:14:47.673860Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_matches3 = ['mexican', 'tequila', 'margarita', 'margaritas', 'mexico', 'pedro', 'azteca', 'paraiso'\n",
    "'mexico','rodeo','rio','maria','mexicanos','coyote','marcos','mama','bravo','viejo','perla','nuevo'\n",
    "'verde', 'gonzalez', 'corona', 'armadillo', 'arriba', 'palmas', 'delicias', 'blanco', 'crespo','tortuga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.685016Z",
     "start_time": "2021-03-02T15:14:47.679229Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_matches4 = ['mexican','mexico','mexicanos','azteca','esperanza','estrada','esperanzas','salero','pinos',\n",
    "                  'maria', 'bravo', 'nuevo', 'progreso', 'delicias', 'comales', 'palmas', 'palenque', 'concordia',\n",
    "                 'china', 'gym', 'paloma', 'rio', 'mex', 'tequila', 'colorado', 'ventana', 'lom', 'garcia', 'paz',\n",
    "                 'chavez', 'paraiso', 'senor', 'oriental', 'fronteras', 'tap', 'aca', 'purisima', 'rodriguez',\n",
    "                 'hernandez', 'sanchez', 'victoria', 'oasis', 'cash', 'pinas', 'yaa', 'meson','agustin',\n",
    "                 'agustin', 'limon', 'alamo', 'slp', 'providencia', 'reyes', 'lom', 'verde', 'perla', 'madrid', \n",
    "                 'delta', 'mama', 'lopez', 'honey', 'laurel', 'california pizza kitchen', 'sauces', 'laguna', \n",
    "              'dolores', 'presidio', 'ver', 'bernal', 'rincon', 'marin', 'palma', 'potrero', 'mid', 'valencia',\n",
    "              'aura', 'kava', 'pueblito', 'castillo', 'tam', 'marcos', 'montecristo', 'tinajas', 'alvarado',\n",
    "              'porvenir', 'nieves', 'mina', 'marin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.690874Z",
     "start_time": "2021-03-02T15:14:47.686947Z"
    }
   },
   "outputs": [],
   "source": [
    "# from redoing the project (March 1st)\n",
    "bad_matches5 = ['china', 'palomas', 'jamaica', 'isla', 'concepcion', 'refugio', 'loma', 'ascension',\n",
    "               'camaron', 'escondida', 'belleza', 'honduras', 'ramirez', 'figueroa', 'florencia', \n",
    "               'bienvenido', 'cna', 'santana', 'tlc',  'trinidad', 'nlu', 'martinez', 'mug', 'andin',\n",
    "               'monterey', 'naranja', 'blanco', 'lto', 'sierra', 'agu', 'tajin', 'lobo', 'sacramento', \n",
    "               'labor', 'jardin', 'jimenez', 'allende', 'santiago', 'lagunitas', 'rayo', 'fortuna', 'coyotes',\n",
    "               'aguila', 'sola', 'carbo', 'jerez', 'letras', 'quintero', 'gomez', 'alfaro', 'parilla',\n",
    "               \"guadalupe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.697449Z",
     "start_time": "2021-03-02T15:14:47.692935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting union of these lists\n",
    "final_bad_matches_list = list(set(bad_matches1) | set(bad_matches2) | set(bad_matches3) | set(bad_matches4) \\\n",
    "                             | set(bad_matches5)) \n",
    "len(final_bad_matches_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the matches to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.702575Z",
     "start_time": "2021-03-02T15:14:47.699039Z"
    }
   },
   "outputs": [],
   "source": [
    "with open ('../my_saved_data/incorrect_matches.pickle', 'wb+') as f:\n",
    "    pickle.dump(final_bad_matches_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually removing the bad entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.732219Z",
     "start_time": "2021-03-02T15:14:47.704090Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in mexico_regional_names_dict.items():\n",
    "    for entry in value:\n",
    "        if entry in final_bad_matches_list:\n",
    "            mexico_regional_names_dict[key].remove(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.737184Z",
     "start_time": "2021-03-02T15:14:47.733929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the dictionary removed 248 values\n"
     ]
    }
   ],
   "source": [
    "# getting count of items\n",
    "counter2 = 0\n",
    "for key, value in mexico_regional_names_dict.items():\n",
    "    counter2 += len(value)\n",
    "counter2\n",
    "print(f\"Cleaning the dictionary removed {counter1 - counter2} values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T15:14:47.744929Z",
     "start_time": "2021-03-02T15:14:47.739123Z"
    }
   },
   "outputs": [],
   "source": [
    "with open ('../my_saved_data/demonym_dictionary.pickle', 'wb+') as f:\n",
    "    pickle.dump(mexico_regional_names_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
