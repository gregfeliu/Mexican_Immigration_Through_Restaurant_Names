{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: **Can we determine the regions from which Mexican immigrants came to NYC through the traces left in restaurant/tacqueria/deli names?**\n",
    "\n",
    "In this notebook, I'll build the database that will connect words to regions and be used to determine the region that a restaurant is connected to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:19.139871Z",
     "start_time": "2021-02-26T18:50:18.632789Z"
    }
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Maps DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:19.155604Z",
     "start_time": "2021-02-26T18:50:19.142306Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://simplemaps.com/data/mx-cities\n",
    "simple_maps = pd.read_csv(\"../demonym_city_data/mx_simple_maps.csv\")\n",
    "\n",
    "simple_maps_clean_df = simple_maps[['city', 'admin']]\n",
    "simple_maps_clean_df2 = change_df_names(simple_maps_clean_df, 'admin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geonames Data \n",
    "https://public.opendatasoft.com/explore/dataset/geonames-all-cities-with-a-population-1000/export/?disjunctive.country&refine.timezone=America%2FMazatlan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:19.981871Z",
     "start_time": "2021-02-26T18:50:19.158257Z"
    }
   },
   "outputs": [],
   "source": [
    "all_geonames = pd.read_csv(\"../demonym_city_data/geonames_data/all_geonames_cities.csv\", sep=';')\n",
    "\n",
    "mex_geonames = all_geonames[all_geonames['Country'] == 'Mexico']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to convert the number for Admin1_Code to a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.005558Z",
     "start_time": "2021-02-26T18:50:19.984018Z"
    }
   },
   "outputs": [],
   "source": [
    "# using simple maps will give us the key\n",
    "regions = list(set(simple_maps.admin.sort_values()))\n",
    "\n",
    "mex_geonames['Admin1 Code'] = mex_geonames['Admin1 Code'].astype(int)\n",
    "mex_geonames['region'] = [regions[x-1] for x in mex_geonames['Admin1 Code']]\n",
    "\n",
    "# removing name since ascii name covers it without accents\n",
    "mex_geonames_clean_df = mex_geonames[['ASCII Name', 'Alternate Names','region']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining values into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.078294Z",
     "start_time": "2021-02-26T18:50:20.007446Z"
    }
   },
   "outputs": [],
   "source": [
    "mex_geonames_clean_df['Alt_names_split'] = [x.split(\",\") if type(x) == str else [] \n",
    "                                            for x in mex_geonames_clean_df['Alternate Names']]\n",
    "\n",
    "mex_geonames_clean_df['ascii_names_list'] = [x.split(\",\") \n",
    "                                            for x in mex_geonames_clean_df['ASCII Name']]\n",
    "\n",
    "mex_geonames_clean_df['all_names_split'] = mex_geonames_clean_df['ascii_names_list'] + mex_geonames_clean_df['Alt_names_split']\n",
    "\n",
    "mex_geonames_clean_df['all_names_split_final'] = [list(set(x)) for x in mex_geonames_clean_df['all_names_split']]\n",
    "mex_geonames_clean_df['all_names_split_unique'] = [list(set(x)) for x in mex_geonames_clean_df['all_names_split_final']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final mex geonames df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.090968Z",
     "start_time": "2021-02-26T18:50:20.080492Z"
    }
   },
   "outputs": [],
   "source": [
    "# mex_geonames_clean_df = \n",
    "mex_geonames_clean_df.drop(columns = ['ASCII Name', 'Alternate Names', 'Alt_names_split',\n",
    "                                     'ascii_names_list', 'all_names_split', 'all_names_split_final'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.126784Z",
     "start_time": "2021-02-26T18:50:20.092897Z"
    }
   },
   "outputs": [],
   "source": [
    "# mex_geonames_clean_df['region'] = [unidecode.unidecode(x) for x in mex_geonames_clean_df['region']]\n",
    "mex_geonames_clean_df2 = change_df_names(mex_geonames_clean_df, 'region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mexican Cities (world_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.166140Z",
     "start_time": "2021-02-26T18:50:20.128790Z"
    }
   },
   "outputs": [],
   "source": [
    "cities = pd.read_csv(\"../demonym_city_data/world-cities-master/data/world-cities.csv\")\n",
    "\n",
    "mexican_cities = cities[cities['country'] == 'Mexico']\n",
    "mexican_cities_clean_df = mexican_cities[['name', 'subcountry']]\n",
    "mexican_cities_clean_df2 = change_df_names(mexican_cities_clean_df, 'subcountry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mexican Demonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was found using the table found in this wikipedia page: https://en.wikipedia.org/wiki/List_of_adjectival_and_demonymic_forms_of_place_names#States_of_Mexico. Then I entered that link into https://wikitable2csv.ggor.de and downloaded the table as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.179917Z",
     "start_time": "2021-02-26T18:50:20.170423Z"
    }
   },
   "outputs": [],
   "source": [
    "mex_demonyms = pd.read_csv(\"../demonym_city_data/mexican_demonyms.csv\", skip_blank_lines=True, skiprows = [1])\n",
    "mex_demonyms.reset_index(inplace=True)\n",
    "mex_demonyms.drop(index=32, inplace=True)\n",
    "mex_demonyms.columns = ['region', \"region_demonym\", \"adjective\", \"demonym\", 'Demonym.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the names into a single list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing items in \"region_in_spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.185555Z",
     "start_time": "2021-02-26T18:50:20.182121Z"
    }
   },
   "outputs": [],
   "source": [
    "mex_demonyms['region'][14] = \"Ciudad de México\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making list that will host all of the demonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.195521Z",
     "start_time": "2021-02-26T18:50:20.192814Z"
    }
   },
   "outputs": [],
   "source": [
    "# once combined with the previous dataframe, we will have a dictionary with each region having a list of names that could refer to it\n",
    "demonyms = [[x] for x in mex_demonyms['region_demonym'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making each cell only have one term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.216899Z",
     "start_time": "2021-02-26T18:50:20.201542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demonyms[0].append(\"aguascalentense\")\n",
    "\n",
    "mex_demonyms['adjective'][0] = \"Hidrocálido/-a\"\n",
    "\n",
    "demonyms[12].append('Jalisquillo')\n",
    "\n",
    "mex_demonyms['demonym'][12] = \"Tapatio/ Tapatia\"\n",
    "\n",
    "# all of the regions_in_english are in the correct format\n",
    "demonyms[20] = ['Pueblan', 'Poblano']\n",
    "\n",
    "# mex_demonyms['adjective'][0] = \"Hidrocálido/-a\"\n",
    "mex_demonyms['demonym'].replace(np.nan, '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.227868Z",
     "start_time": "2021-02-26T18:50:20.218940Z"
    }
   },
   "outputs": [],
   "source": [
    "## Making all of the -a names to be a seperate entry\n",
    "for x in range(0, len(mex_demonyms)):\n",
    "    multi_adjective = re.match(r\"(\\w+)[o]\\/(?=(\\-?|\\s|\\s\\-)a)(.+)\", mex_demonyms['adjective'][x])\n",
    "    if multi_adjective:\n",
    "        mex_demonyms['adjective'][x] = multi_adjective.group(1) + \"o\" + '/' \\\n",
    "        + multi_adjective.group(1) + \"a\"\n",
    "    multi_dem = re.match(r\"\\\"?(\\w+)[o]\\/(?=(\\-?|\\s|\\s\\-)a)\", mex_demonyms['demonym'][x])\n",
    "    if multi_dem:\n",
    "        mex_demonyms['demonym'][x] = multi_dem.group(1) + \"o\" + '/' \\\n",
    "        + multi_dem.group(1) + \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.234665Z",
     "start_time": "2021-02-26T18:50:20.229789Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting all of items to either be a single name or single name/-a\n",
    "for x in range(0, len(mex_demonyms)):\n",
    "    split_adj = mex_demonyms['adjective'][x].split(\"/\")\n",
    "    for y in split_adj:\n",
    "        demonyms[x].append(y)\n",
    "    split_dem = mex_demonyms['demonym'][x].split(\"/\")\n",
    "    for z in split_dem:\n",
    "        a = z.strip('\"\"')\n",
    "        demonyms[x].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.239643Z",
     "start_time": "2021-02-26T18:50:20.236451Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making the demonyms data only have unique entries\n",
    "unique_demonyms = [list(set(item)) for item in demonyms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the demonyms connect to a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.246416Z",
     "start_time": "2021-02-26T18:50:20.241871Z"
    }
   },
   "outputs": [],
   "source": [
    "demonyms_w_region = list(zip(mex_demonyms['region'], demonyms))\n",
    "demonyms_w_regions_df = pd.DataFrame(data = demonyms_w_region, columns=['State', 'Demonyms'])\n",
    "demonyms_w_regions_df2 = change_df_names(demonyms_w_regions_df, 'State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Mexico_names dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.251665Z",
     "start_time": "2021-02-26T18:50:20.248297Z"
    }
   },
   "outputs": [],
   "source": [
    "english_region_names = list(mexican_cities_clean_df.region.unique())\n",
    "mexico_regional_names_dict = {unidecode.unidecode(x):[] for x in english_region_names} # removing any accents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking that region names match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.258018Z",
     "start_time": "2021-02-26T18:50:20.253319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ciudad de Mexico', 'Coahuila de Zaragoza', 'Michoacan de Ocampo']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_matches_simple_maps = match_region_names(mexico_regional_names_dict, simple_maps_clean_df2)\n",
    "bad_matches_simple_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.264375Z",
     "start_time": "2021-02-26T18:50:20.259745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coahuila de Zaragoza', 'Michoacan de Ocampo', 'Ciudad de Mexico']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_matches_mex_geonames_clean_df = match_region_names(mexico_regional_names_dict, \n",
    "                                                       mex_geonames_clean_df2)\n",
    "bad_matches_mex_geonames_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.270397Z",
     "start_time": "2021-02-26T18:50:20.266531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_matches_mexican_cities_clean_df = match_region_names(mexico_regional_names_dict, \n",
    "                                                       mexican_cities_clean_df2)\n",
    "bad_matches_mexican_cities_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.276853Z",
     "start_time": "2021-02-26T18:50:20.272320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coahuila de Zaragoza', 'State of Mexico', 'Ciudad de Mexico']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_matches_demonyms_w_regions_df = match_region_names(mexico_regional_names_dict, \n",
    "                                                       demonyms_w_regions_df2)\n",
    "bad_matches_demonyms_w_regions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing incorrect col_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.284140Z",
     "start_time": "2021-02-26T18:50:20.278534Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_maps_clean_df3 = replace_col_values_in_df(simple_maps_clean_df2)\n",
    "mex_geonames_clean_df3 = replace_col_values_in_df(mex_geonames_clean_df2)\n",
    "mexican_cities_clean_df3 = replace_col_values_in_df(mexican_cities_clean_df2)\n",
    "demonyms_w_regions_df3 = replace_col_values_in_df(demonyms_w_regions_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Values to the Larger Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.607634Z",
     "start_time": "2021-02-26T18:50:20.285932Z"
    }
   },
   "outputs": [],
   "source": [
    "mexico_regional_names_dict = add_data_to_dictionary(simple_maps_clean_df3 ,mexico_regional_names_dict)\n",
    "mexico_regional_names_dict = add_data_to_dictionary(mex_geonames_clean_df3 ,mexico_regional_names_dict)\n",
    "mexico_regional_names_dict = add_data_to_dictionary(mexican_cities_clean_df3 ,mexico_regional_names_dict)\n",
    "mexico_regional_names_dict = add_data_to_dictionary(demonyms_w_regions_df3 ,mexico_regional_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.612346Z",
     "start_time": "2021-02-26T18:50:20.609486Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for key, value in mexico_regional_names_dict.items():\n",
    "    counter += len(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.617557Z",
     "start_time": "2021-02-26T18:50:20.614162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22217"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the Larger Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.780459Z",
     "start_time": "2021-02-26T18:50:20.619201Z"
    }
   },
   "outputs": [],
   "source": [
    "mexico_regional_names_dict = clean_dictionary_values(mexico_regional_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.788792Z",
     "start_time": "2021-02-26T18:50:20.782287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the dictionary removed 5739 values\n"
     ]
    }
   ],
   "source": [
    "# getting count of items\n",
    "counter1 = 0\n",
    "for key, value in mexico_regional_names_dict.items():\n",
    "    for thing in value:\n",
    "        counter1 += 1\n",
    "counter1\n",
    "\n",
    "print(f\"Cleaning the dictionary removed {counter - counter1} values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing entries that are ambiguous/mistakenly connected to a region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying bad matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.793294Z",
     "start_time": "2021-02-26T18:50:20.790553Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_matches1 = ['mexican', 'tequila', 'margarita', 'margaritas', 'mexico', 'pedro', 'azteca', 'paraiso'\n",
    "'mexico','rodeo','rio','maria','mexicanos','coyote','marcos','mama','bravo','viejo','perla','nuevo'\n",
    "'verde', 'gonzalez', 'corona', 'armadillo', 'arriba', 'palmas', 'delicias', 'blanco', 'crespo','tortuga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.799782Z",
     "start_time": "2021-02-26T18:50:20.794987Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_matches2 = ['mexican','mexico','mexicanos','azteca','esperanza','estrada','esperanzas','salero','pinos',\n",
    "                  'maria', 'bravo', 'nuevo', 'progreso', 'delicias', 'comales', 'palmas', 'palenque', 'concordia',\n",
    "                 'china', 'gym', 'paloma', 'rio', 'mex', 'tequila', 'colorado', 'ventana', 'lom', 'garcia', 'paz',\n",
    "                 'chavez', 'paraiso', 'senor', 'oriental', 'fronteras', 'tap', 'aca', 'purisima', 'rodriguez',\n",
    "                 'hernandez', 'sanchez', 'victoria', 'oasis', 'cash', 'pinas', 'yaa',  'meson','agustin',\n",
    "                 'agustin', 'limon', 'alamo', 'slp', 'providencia', 'reyes', 'lom', 'verde', 'perla', 'madrid', \n",
    "                 'delta', 'mama', 'lopez', 'honey', 'laurel', 'california pizza kitchen', 'sauces', 'laguna', \n",
    "              'dolores', 'presidio', 'ver', 'bernal', 'rincon', 'marin', 'palma', 'potrero', 'mid', 'valencia',\n",
    "              'aura', 'kava', 'pueblito', 'castillo', 'tam', 'marcos', 'montecristo', 'tinajas', 'alvarado',\n",
    "              'porvenir', 'nieves', 'mina', 'marin', \"alamos\", 'reforma', 'jal', 'margaritas', 'california']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.804404Z",
     "start_time": "2021-02-26T18:50:20.801512Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_matches3 = ['mexican', 'tequila', 'margarita', 'margaritas', 'mexico', 'pedro', 'azteca', 'paraiso'\n",
    "'mexico','rodeo','rio','maria','mexicanos','coyote','marcos','mama','bravo','viejo','perla','nuevo'\n",
    "'verde', 'gonzalez', 'corona', 'armadillo', 'arriba', 'palmas', 'delicias', 'blanco', 'crespo','tortuga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.810656Z",
     "start_time": "2021-02-26T18:50:20.806068Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_matches4 = ['mexican','mexico','mexicanos','azteca','esperanza','estrada','esperanzas','salero','pinos',\n",
    "                  'maria', 'bravo', 'nuevo', 'progreso', 'delicias', 'comales', 'palmas', 'palenque', 'concordia',\n",
    "                 'china', 'gym', 'paloma', 'rio', 'mex', 'tequila', 'colorado', 'ventana', 'lom', 'garcia', 'paz',\n",
    "                 'chavez', 'paraiso', 'senor', 'oriental', 'fronteras', 'tap', 'aca', 'purisima', 'rodriguez',\n",
    "                 'hernandez', 'sanchez', 'victoria', 'oasis', 'cash', 'pinas', 'yaa', 'meson','agustin',\n",
    "                 'agustin', 'limon', 'alamo', 'slp', 'providencia', 'reyes', 'lom', 'verde', 'perla', 'madrid', \n",
    "                 'delta', 'mama', 'lopez', 'honey', 'laurel', 'california pizza kitchen', 'sauces', 'laguna', \n",
    "              'dolores', 'presidio', 'ver', 'bernal', 'rincon', 'marin', 'palma', 'potrero', 'mid', 'valencia',\n",
    "              'aura', 'kava', 'pueblito', 'castillo', 'tam', 'marcos', 'montecristo', 'tinajas', 'alvarado',\n",
    "              'porvenir', 'nieves', 'mina', 'marin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.814790Z",
     "start_time": "2021-02-26T18:50:20.812344Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting union of these lists\n",
    "final_bad_matches_list = list(set(bad_matches1) | set(bad_matches2) | set(bad_matches3) | set(bad_matches4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.819806Z",
     "start_time": "2021-02-26T18:50:20.816434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_bad_matches_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually removing the bad entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.842209Z",
     "start_time": "2021-02-26T18:50:20.821528Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in mexico_regional_names_dict.items():\n",
    "    for entry in value:\n",
    "        if entry in final_bad_matches_list:\n",
    "            mexico_regional_names_dict[key].remove(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.847096Z",
     "start_time": "2021-02-26T18:50:20.843857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the dictionary removed 159 values\n"
     ]
    }
   ],
   "source": [
    "# getting count of items\n",
    "counter2 = 0\n",
    "for key, value in mexico_regional_names_dict.items():\n",
    "    counter2 += len(value)\n",
    "counter2\n",
    "print(f\"Cleaning the dictionary removed {counter1 - counter2} values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sure no entry is used twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.851083Z",
     "start_time": "2021-02-26T18:50:20.848620Z"
    }
   },
   "outputs": [],
   "source": [
    "all_values_separate = list(mexico_regional_names_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.882033Z",
     "start_time": "2021-02-26T18:50:20.852843Z"
    }
   },
   "outputs": [],
   "source": [
    "duplicates = []\n",
    "for idx, sublist in enumerate(all_values_separate):\n",
    "    big_list = []\n",
    "    for x in range(32):\n",
    "        if x != idx:\n",
    "            big_list.extend(all_values_separate[x])\n",
    "    sublist_duplicates = list(set(sublist) & set(big_list))\n",
    "    duplicates.append(sublist_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.886920Z",
     "start_time": "2021-02-26T18:50:20.883675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicates[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.892049Z",
     "start_time": "2021-02-26T18:50:20.888601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_values_separate[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.896613Z",
     "start_time": "2021-02-26T18:50:20.893633Z"
    }
   },
   "outputs": [],
   "source": [
    "# only the first entry has no repeats\n",
    "for idx, item in enumerate([duplicates, all_values_separate]):\n",
    "    if len(item[0][idx]) == len(item[1][idx]):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:50:20.901879Z",
     "start_time": "2021-02-26T18:50:20.898305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# now I'm confused\n",
    "for idx, item in enumerate([duplicates, all_values_separate]):\n",
    "    if len(item[0][idx]) != len(item[1][idx]):\n",
    "        print(len(item[1][idx]) - len(item[0][idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T18:51:41.106094Z",
     "start_time": "2021-02-26T18:51:41.099208Z"
    }
   },
   "outputs": [],
   "source": [
    "with open ('../my_saved_data/demonym_dictionary.pickle', 'wb+') as f:\n",
    "    pickle.dump(mexico_regional_names_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
